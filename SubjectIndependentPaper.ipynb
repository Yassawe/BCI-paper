{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import geomstats as gs\n",
    "import geomstats.geometry.spd_matrices as spd\n",
    "import pickle\n",
    "from scipy.signal import butter, lfilter\n",
    "from geomstats.learning.frechet_mean import FrechetMean\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from scipy.stats import wilcoxon\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format"
   ]
  },
  {
   "source": [
    "# Globally used things"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCSP:\n",
    "    def __init__(self, metric, nchannels, clf):\n",
    "        self.metric = metric\n",
    "        self.nchannels = nchannels\n",
    "        self.clf=clf()\n",
    "        self.V=None\n",
    "        self.n=None\n",
    "    \n",
    "    def estimateMeans(self, classSpecificCOV):\n",
    "        if self.metric==\"classic\":\n",
    "            class0_avg = sum(classSpecificCOV[0])/len(classSpecificCOV[0])\n",
    "            class1_avg = sum(classSpecificCOV[1])/len(classSpecificCOV[1])\n",
    "            return [class0_avg, class1_avg]\n",
    "        elif self.metric==\"AIRM\":\n",
    "            estimator = FrechetMean(spd.SPDMetricAffine(n=self.nchannels), max_iter=64)\n",
    "        elif self.metric==\"LEM\":\n",
    "            estimator = FrechetMean(spd.SPDMetricLogEuclidean(n=self.nchannels), max_iter=64)\n",
    "        elif self.metric==\"BW\":\n",
    "            estimator = FrechetMean(spd.SPDMetricBuresWasserstein(n=self.nchannels), max_iter=64) #doesn't work yet\n",
    "        else:\n",
    "            raise Exception(\"Not implemented metric\")\n",
    "            \n",
    "        means = []\n",
    "        \n",
    "        for COV in classSpecificCOV:\n",
    "            estimator.fit(COV)\n",
    "            mean = estimator.estimate_\n",
    "            means.append(mean)\n",
    "        return means\n",
    "    \n",
    "    def separate_classes(self, X, Y):\n",
    "        classSpecificCOV = []\n",
    "        for i in range(2): \n",
    "            ind = np.where(Y==i)[0]\n",
    "            classCOV = X[ind]\n",
    "            classSpecificCOV.append(classCOV)\n",
    "        return classSpecificCOV\n",
    "    \n",
    "    def CSP(self, means, n):\n",
    "        _,V = la.eigh(means[0], means[0]+means[1])\n",
    "        V = np.concatenate((V[:, :n], V[:, -n:]), axis=1)\n",
    "        return V\n",
    "    \n",
    "    def applyCSP(self, trial, V):\n",
    "        a = np.dot(np.dot(V.T, trial), V) \n",
    "        f = np.log(np.diagonal(a)/np.trace(a)) #logvariance features \n",
    "        return f\n",
    "    \n",
    "    def train(self, trainCOV, trainLabels, n=3):\n",
    "        \n",
    "        classSpecificCOV = self.separate_classes(trainCOV, trainLabels)\n",
    "        means = self.estimateMeans(classSpecificCOV)\n",
    "        \n",
    "        V=self.CSP(means, n)\n",
    "        self.V=V\n",
    "        self.n=n\n",
    "        train_features = np.empty((len(trainCOV), 2*n))\n",
    "        \n",
    "        for i in range(len(trainCOV)):\n",
    "            trial = trainCOV[i]\n",
    "            train_features[i] = self.applyCSP(trial, V)\n",
    "        \n",
    "        self.clf.fit(train_features, trainLabels)\n",
    "    \n",
    "    def predict(self, testCOV):\n",
    "        V = self.V\n",
    "        n = self.n\n",
    "        \n",
    "        if V is None or n is None:\n",
    "            raise Exception('Train the model first')\n",
    "        \n",
    "        test_features = np.empty((len(testCOV), 2*n))\n",
    "        for i in range(len(testCOV)):\n",
    "            trial = testCOV[i]\n",
    "            test_features[i] = self.applyCSP(trial, V)\n",
    "        \n",
    "        prediction = self.clf.predict(test_features)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base classifiers \n",
    "c_csp = RCSP('classic', 20, LDA)\n",
    "airm_csp = RCSP('AIRM', 20, LDA)\n",
    "lem_csp = RCSP('LEM', 20, LDA)\n",
    "bw_csp = RCSP('BW', 20, LDA)\n",
    "\n",
    "def count_accuracy(predicted, true, dec_places=2):\n",
    "    err_count = 0\n",
    "    for j in range(len(true)):\n",
    "        if predicted[j]!=true[j]:\n",
    "            err_count+=1\n",
    "    acc = (1-err_count/len(true))*100\n",
    "    acc = round(acc, dec_places)\n",
    "    return acc\n",
    "\n",
    "SubjectsCOV1, SubjectsY1 = pickle.load(open('datasets/54COVSess01.pickle','rb'))\n",
    "SubjectsCOV2, SubjectsY2 = pickle.load(open('datasets/54COVSess02.pickle','rb'))"
   ]
  },
  {
   "source": [
    "# Majority Vote"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(SubjectsCOV, SubjectsY, n):\n",
    "    df = pd.DataFrame(index=list(range(1, 55))+['Average', 'p-value'], columns=['Classic CSP', 'AIRM CSP', 'LEM CSP', 'BW CSP', 'Majority Vote'])\n",
    "    \n",
    "    c_results = [] #very sloppy coding, did not prioritize clean code\n",
    "    a_results = []\n",
    "    l_results = []\n",
    "    bw_results = []\n",
    "    m_results = []\n",
    "    \n",
    "    for i in range(len(SubjectsCOV)):\n",
    "        SC = deepcopy(SubjectsCOV)\n",
    "        SY = deepcopy(SubjectsY)\n",
    "            \n",
    "        testCOV = SC.pop(i)\n",
    "        testY = SY.pop(i)\n",
    "            \n",
    "        trainCOV = None\n",
    "        trainY = None\n",
    "\n",
    "        for j in range(len(SubjectsCOV)-1):\n",
    "            if trainCOV is None:\n",
    "                trainCOV = SC[j]\n",
    "                trainY = SY[j]\n",
    "            else:\n",
    "                trainCOV = np.concatenate((trainCOV, SC[j]))\n",
    "                trainY = np.concatenate((trainY, SY[j]))\n",
    "        \n",
    "        c_csp.train(trainCOV, trainY, n=n)\n",
    "        c_res = c_csp.predict(testCOV)\n",
    "\n",
    "        airm_csp.train(trainCOV, trainY, n=n)\n",
    "        a_res = airm_csp.predict(testCOV)\n",
    "\n",
    "        lem_csp.train(trainCOV, trainY, n=n)\n",
    "        l_res = lem_csp.predict(testCOV)\n",
    "\n",
    "        bw_csp.train(trainCOV, trainY, n=n)\n",
    "        bw_res = bw_csp.predict(testCOV)\n",
    "\n",
    "        res = np.column_stack((a_res, l_res, bw_csp))\n",
    "        N = len(res)\n",
    "\n",
    "        majority = np.empty(N, dtype='uint8')\n",
    "\n",
    "        for j in range(N):\n",
    "            majority[j] = np.argmax(np.bincount(res[j]))\n",
    "    \n",
    "        c_results.append(count_accuracy(c_res, testY))\n",
    "        a_results.append(count_accuracy(a_res, testY))\n",
    "        l_results.append(count_accuracy(l_res, testY))\n",
    "        bw_results.append(count_accuracy(bw_res, testY))\n",
    "        m_results.append(count_accuracy(majority, testY))\n",
    "    \n",
    "    c_results.append(sum(c_results)/len(c_results)) #чуть чуть клоунский код, но работает\n",
    "    a_results.append(sum(a_results)/len(a_results))\n",
    "    l_results.append(sum(l_results)/len(l_results))\n",
    "    bw_results.append(sum(bw_results)/len(bw_results))\n",
    "    m_results.append(sum(m_results)/len(m_results))\n",
    "\n",
    "    a_results.append(wilcoxon(a_results[:-1], c_results[:-1])[1])\n",
    "    l_results.append(wilcoxon(l_results[:-1], c_results[:-1])[1])\n",
    "    bw_results.append(wilcoxon(bw_results[:-1], c_results[:-1])[1])\n",
    "    m_results.append(wilcoxon(m_results[:-1], c_results[:-1])[1])\n",
    "\n",
    "\n",
    "    df['Classic CSP'] = c_results + [None]\n",
    "    df['AIRM CSP'] = a_results\n",
    "    df['LEM CSP'] = l_results\n",
    "    df['BW CSP'] = bw_results\n",
    "    df['Majority Vote'] = m_results\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "source": [
    "## Session 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv1_2 = majority_vote(SubjectsCOV1, SubjectsY1, 2)\n",
    "dfmv1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv1_3 = majority_vote(SubjectsCOV1, SubjectsY1, 3)\n",
    "dfmv1_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv1_4 = majority_vote(SubjectsCOV1, SubjectsY1, 4)\n",
    "dfmv1_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv1_5 = majority_vote(SubjectsCOV1, SubjectsY1, 5)\n",
    "dfmv1_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsSess01 = [dfmv1_2, dfmv1_3, dfmv1_4, dfmv1_5]\n",
    "\n",
    "filename = 'datasets/MVResultsSess01.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(ResultsSess01, outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "source": [
    "## Session 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv2_2 = majority_vote(SubjectsCOV2, SubjectsY2, 2)\n",
    "dfmv2_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv2_3 = majority_vote(SubjectsCOV2, SubjectsY2, 2)\n",
    "dfmv2_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv2_4 = majority_vote(SubjectsCOV2, SubjectsY2, 4)\n",
    "dfmv2_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmv2_5 = majority_vote(SubjectsCOV2, SubjectsY2, 5)\n",
    "dfmv2_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsSess02 = [dfmv2_2, dfmv2_3, dfmv2_4, dfmv2_5]\n",
    "\n",
    "filename = 'datasets/MVResultsSess02.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(ResultsSess02, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "source": [
    "# Bootstrap Mean Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCSP_bootstrap(RCSP):\n",
    "    def train(self, trainCOV, trainLabels, n=3, btsp_size=0.6, btsp_n=10):\n",
    "        btsp_means = np.zeros((2, btsp_n, self.nchannels, self.nchannels))\n",
    "        trials = len(trainCOV)\n",
    "        idxs = list(range(trials))\n",
    "        \n",
    "        for i in range(btsp_n):\n",
    "            idx = np.random.choice(idxs, int(btsp_size*trials))\n",
    "            subsetCOV = trainCOV[idx]\n",
    "            subsetY = trainLabels[idx]\n",
    "            \n",
    "            classSpecificCOV = self.separate_classes(subsetCOV, subsetY)\n",
    "            means = self.estimateMeans(classSpecificCOV)\n",
    "            btsp_means[0, i, :, :] = means[0]\n",
    "            btsp_means[1, i, :, :] = means[1]\n",
    "        \n",
    "        btsp_means = self.estimateMeans(btsp_means)\n",
    "        \n",
    "        V = self.CSP(btsp_means, n)\n",
    "        self.V=V\n",
    "        self.n=n\n",
    "        \n",
    "        train_features = np.empty((len(trainCOV), 2*n))\n",
    "        \n",
    "        for i in range(len(trainCOV)):\n",
    "            trial = trainCOV[i]\n",
    "            train_features[i] = self.applyCSP(trial, V)\n",
    "        \n",
    "        self.clf.fit(train_features, trainLabels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rcsp_b = RCSP_bootstrap(\"classic\", 20, LDA)\n",
    "a_rcsp_b = RCSP_bootstrap(\"AIRM\", 20, LDA)\n",
    "l_rcsp_b = RCSP_bootstrap(\"LEM\", 20, LDA)\n",
    "bw_rcsp_b = RCSP_bootstrap(\"BW\", 20, LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_estimation(SubjectsCOV, SubjectsY, n, btsp_size, btsp_n):\n",
    "    df = pd.DataFrame(index=list(range(1, 55))+['Average', 'p-values'], columns=['Bootstraped Classic CSP', 'Bootstraped AIRM CSP', 'Bootstraped LEM CSP', 'Bootstrapped BW CSP', 'Majority Vote'])\n",
    "    \n",
    "    c_results = []\n",
    "    a_results = []\n",
    "    l_results = []\n",
    "    bw_results = []\n",
    "    m_results = []\n",
    "    \n",
    "    for i in range(len(SubjectsCOV)):    \n",
    "        SC = deepcopy(SubjectsCOV)\n",
    "        SY = deepcopy(SubjectsY)    \n",
    "        testCOV = SC.pop(i)\n",
    "        testY = SY.pop(i)\n",
    "        \n",
    "        trainCOV = None\n",
    "        trainY = None\n",
    "        \n",
    "        for j in range(len(SubjectsCOV)-1):\n",
    "            if trainCOV is None:\n",
    "                trainCOV = SC[j]\n",
    "                trainY = SY[j]\n",
    "            else:\n",
    "                trainCOV = np.concatenate((trainCOV, SC[j]))\n",
    "                trainY = np.concatenate((trainY, SY[j]))\n",
    "        \n",
    "        \n",
    "        c_rcsp_b.train(trainCOV, trainY, n, btsp_size, btsp_n)\n",
    "        c_res = c_rcsp_b.predict(testCOV)\n",
    "        \n",
    "        a_rcsp_b.train(trainCOV, trainY, n, btsp_size, btsp_n)\n",
    "        a_res = a_rcsp_b.predict(testCOV)\n",
    "        \n",
    "        l_rcsp_b.train(trainCOV, trainY, n, btsp_size, btsp_n)\n",
    "        l_res = l_rcsp_b.predict(testCOV)\n",
    "\n",
    "        bw_rcsp_b.train(trainCOV, trainY, n, btsp_size, btsp_n)\n",
    "        bw_res = bw_rcsp_b.predict(testCOV)\n",
    "        \n",
    "        res = np.column_stack((a_res, l_res, bw_csp))\n",
    "\n",
    "        N = len(res)\n",
    "\n",
    "        majority = np.empty(N, dtype='uint8')\n",
    "\n",
    "        for j in range(N):\n",
    "            majority[j] = np.argmax(np.bincount(res[j]))\n",
    "\n",
    "\n",
    "        c_results.append(count_accuracy(c_res, testY))\n",
    "        a_results.append(count_accuracy(a_res, testY))\n",
    "        l_results.append(count_accuracy(l_res, testY))\n",
    "        bw_results.append(count_accuracy(bw_res, testY))\n",
    "        m_results.append(count_accuracy(majority, testY))\n",
    "        \n",
    "    c_results.append(sum(c_results)/len(c_results))\n",
    "    a_results.append(sum(a_results)/len(a_results))\n",
    "    l_results.append(sum(l_results)/len(l_results))\n",
    "    bw_results.append(sum(bw_results)/len(bw_results))\n",
    "    m_results.append(sum(m_results)/len(m_results))\n",
    "    \n",
    "\n",
    "    a_results.append(wilcoxon(a_results[:-1], c_results[:-1])[1])\n",
    "    l_results.append(wilcoxon(l_results[:-1], c_results[:-1])[1])\n",
    "    bw_results.append(wilcoxon(bw_results[:-1], c_results[:-1])[1])\n",
    "    m_results.append(wilcoxon(m_results[:-1], c_results[:-1])[1])\n",
    "    \n",
    "    df['Bootstraped Classic CSP'] = c_results + [None]\n",
    "    df['Bootstraped AIRM CSP'] = a_results\n",
    "    df['Bootstraped LEM CSP'] = l_results\n",
    "    df['Bootstraped BW CSP'] = bw_results\n",
    "    df['Majority Vote'] = m_results\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btsp_size = 0.6\n",
    "btsp_n = 10"
   ]
  },
  {
   "source": [
    "## Session 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt1_2 = bootstrap_estimation(SubjectsCOV1, SubjectsY1, 2, btsp_size, btsp_n)\n",
    "dfbt1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt1_3 = bootstrap_estimation(SubjectsCOV1, SubjectsY1, 3, btsp_size, btsp_n)\n",
    "dfbt1_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt1_4 = bootstrap_estimation(SubjectsCOV1, SubjectsY1, 4, btsp_size, btsp_n)\n",
    "dfbt1_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt1_5 = bootstrap_estimation(SubjectsCOV1, SubjectsY1, 5, btsp_size, btsp_n)\n",
    "dfbt1_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsSess01 = [dfbt1_2, dfbt1_3, dfbt1_4, dfbt1_5]\n",
    "\n",
    "filename = 'datasets/BTResultsSess01.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(ResultsSess01, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "source": [
    "## Session 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt2_2 = bootstrap_estimation(SubjectsCOV2, SubjectsY2, 2, btsp_size, btsp_n)\n",
    "dfbt2_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt2_3 = bootstrap_estimation(SubjectsCOV2, SubjectsY2, 3, btsp_size, btsp_n)\n",
    "dfbt2_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt2_4 = bootstrap_estimation(SubjectsCOV2, SubjectsY2, 4, btsp_size, btsp_n)\n",
    "dfbt2_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbt2_5 = bootstrap_estimation(SubjectsCOV2, SubjectsY2, 5, btsp_size, btsp_n)\n",
    "dfbt2_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsSess01 = [dfbt2_2, dfbt2_3, dfbt2_4, dfbt2_5]\n",
    "\n",
    "filename = 'datasets/BTResultsSess02.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(ResultsSess01, outfile)\n",
    "outfile.close()"
   ]
  }
 ]
}